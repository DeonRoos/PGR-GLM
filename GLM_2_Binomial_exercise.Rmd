---
title: 'Exercise'
# author: TCornulier
output: 
  html_document:
    toc: false
    code_folding: hide
editor_options: 
  chunk_output_type: console
---


```{r setup, echo=FALSE, purl = FALSE}
knitr::opts_chunk$set(echo=TRUE, message = FALSE, warning = FALSE, eval = FALSE, cache = FALSE)

SOLUTIONS <- FALSE
```

\  

# Exercise: Binomial GLM - understanding MRSE

\  

For the GLM exercises, we'll use the workflow we suggested in the first GLM overview lecture as a template, specifically:

1. Know your research question!

2. Think about your response variable (stochastic).

3. Think about the process behind the data (deterministic).

4. Understand the data that you’ve collected (plot it!)

5. Combine into a model that can answer your question.

6. Fit the model.

7. Check your assumption(s).

8. Answer your question.

\

1\. Know your research question!

The researchers who collected this data wanted to understand how a policy decision, as well as other covariates, were associated with the prevalence of Multi-drug Resistant *Staphylococcus epidermidis* (MRSE, a relative of MRSA) amongst patients in different Intensive Care Unit (ICU) wards. Data was collected from all 210 ICU wards in the UK and included the total number of patients in each ICU ward (`total_patients`) as well as how many of them were MRSE positive (`mrse`). 

Specifically, the researchers wanted to understand how three explanatory variables were assocaited with the prevalence of MRSE: 1) the number of staff working in an ICU (`staff`); 2) current capacity of the ward (`capacity`, expressed as a proportion of beds currently occupied); and 3) whether or not the respective hospital board had implemented a policy concerning the reduced use of Chlorhexidine bathing (`policy`). Chlorhexidine usage was of primary interest, as the researchers believed this bathing was, in part, responsible for increasing prevalence of MRSE due to overuse leading to anti-microbial resistance (since chlorhexidine is an anti-microbial agent). Additionally, the researchers felt it was likely that the effectiveness of the policy depended on the number of ICU staff to implement it (so would require an interaction between `staff` and `policy`). In total, data was collected from 210 ICU wards ($n = 210$), where each observation is from a single ICU ward in a hospital.

As concisely as possible, write down the research question that can be answered with our analysis.

```{r Q1, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
# How do ward capacity, staff numbers, chlorhexidine policy, and an interaction 
# between chlorhexidine policy and staff numbers, relate with the proportion of 
# patients infected with MRSE?
```

2\. Think about your response variable (the stochastic element).

From the information provided in the brief above, we are already able to determine a suitable distribution to use when fitting the model (as before, ignore that today's class is called $Binomial$ GLMs). Here, we've been told two pieces of information that help us determine that a $Binomial$ is a sensible distribution:

1. We have a count of "successes" (here, "success" is paradoxically a patient who is infected with MRSE)

2. We have the total number of patients present on the ward.

So, we know the minimum count of "successes" (i.e. infected patients) will be zero but we also know we have an upper bound; We can't have more patients infected with MRSE than we have patients on the ward. This is the type of data that a $Binomial$ distribution excels in accounting for. Our stochastic element of the model would therefore be:

$y_i \sim Binomial(p_i, k_i)$

Where $y$ is the number of MRSE positive patients in ICU ward $i$, generated according to a $Binomial$ distribution, with probability $p$ and number of trials $k$.

\

3\. Think about the process behind the data (the deterministic element).

As with yesterday's practical, spending a couple of minutes thinking about the process that goes into why some wards may have higher prevalence of MRSE compared to others is mind boggling. We could spend years trying to map out that complexity, and indeed that's what lots of researchers try to do. Here, the researchers have presented us with a suitably focused set of covariates and a razor sharp research question, meaning we can skip the "existential crises" phase and jump straight into the modelling. While skipping this is useful for teaching purposes, it really is worth emphasising, again, that this is where the majority of statistical analysis happens. Thinking very carefully about the process behind how the data is "generated" (called the *Data Generating Process*), and how we want to represent this in our models.

\  

4\. Understand the data that you’ve collected (plot it!)

Import the data file 'mrse.txt' into R and take a look at the structure of this dataframe. Given you have never seen this data before, it's really important that you familiarise yourself with any nuances.

Keep the tips and tricks you used in yesterday's practical and feel free to use them again here.

A bit of advice for visualising $Binomial$ data; it can be easier to visualise if you create a new column in your dataset which is the proportion of success. Calculated as the number of successes divided by the number of trials (using the terminology of the $Binomial$ distribution). If in doubt, as for help. 

Also, do not feel as though you need to replicate the figures shown here. They are included to show how *I* visualised the data, but I am sure many of you will be able to do a better job. The figures shown below are purely to give you inspiration.


```{r}
icu <- read.table(file= "./data/mrse.txt", header= TRUE)

icu$proportion <- icu$mrse / icu$total_patients

boxplot(icu$proportion ~ icu$policy)
plot(icu$proportion ~ icu$capacity)
```











\  

# Exercise: Binomial (Proportions) GLM - mites survival

\  

The data for this exercise were collected for an experiment to test the toxicity of different chemicals at various concentrations to a species of mite. The aim was to determine whether the proportion of mites surviving was related to the concentration of the chemical and whether this relationship depended on the type of chemical the mites were exposed to. We will be using a binomial GLM again for this example, but this time we will be using it to model proportion data, from counts of "successes" (= mite survival, unless you don't like mites), and "failures" (= mite death).

* Variables:
  + `ID` index of the observations
  + `Concentration`: Concentration of the chemical
  + `Toxic`: Chemical type
  + `Dead_mites`: Number of dead mites in assay
  + `Total`: Initial number of mites in assay
  + `Proportion`= `Dead_mites / Total`

\  

As in previous exercises, either create a new R script (perhaps call it GLM_BinomProps) or continue with your previous R script in your RStudio Project. Again, make sure you include any metadata you feel is appropriate (title, description of task, date of creation etc) and  don't forget to comment out your metadata with a `#` at the beginning of the line. 

\  

1\. Import the data file 'DrugsMites.txt' into R. We want to model the variable Toxic as a categorical predictor with 4 levels, so create a new variable with Toxic as a factor.

\  

```{r Q1.1, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
Mites<- read.delim("./data/DrugsMites.txt")
str(Mites)

Mites$fToxic<- factor(Mites$Toxic)

str(Mites)
```

\  

2\. Perform the usual graphical data exploration, looking for outliers, relationships between predictors, and between response and predictors etc. You can use the variable `Proportion` in the data frame for these plots.

\  

```{r Q2, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide")}
# Outliers Y
boxplot(Mites$Proportion) # not very useful for this data set
dotchart(Mites$Proportion)

# Outliers X
dotchart(Mites$Concentration)

# Correlations between predictors
plot(jitter(Mites$Concentration), jitter(Mites$Toxic))

# Toxics 2 and 3 have not been assayed at the highest concentrations
# but have had more trials at the lower concentrations

# Relationships
boxplot(Proportion ~ Toxic, data= Mites)
with(Mites, plot(x= Concentration, y= Proportion))

# Since lots of proportions have the same values, we can also add
# a bit of noise to the coordinates in the previous plot, to limit overlap:
with(Mites, plot(x= jitter(Concentration), y= jitter(Proportion)))

coplot(jitter(Proportion) ~ jitter(Concentration) | fToxic, data= Mites)

# looks like researchers stopped increasing concentration of a chemical when they had
# reached ~ 100 % mortality in assays

```

\  

3\. In order to model the proportion of mites surviving, create a new variable (called something creative like Living_mites for example) representing the number of surviving mites by differencing the two variables Dead_mites and Total.

\  

```{r Q3, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
Mites$Living_mites<- Mites$Total - Mites$Dead_mites

table(Mites$Total)
```

\  

4\. We can now use this new variable when specifying a binomial GLM. Recall from the lecture that the response variable should be a data frame consisting  of two columns, cbind(Living_mites, Dead_mites). Ask if in doubt. If you hate mites you could also swap the order of the two columns: you would then be modelling the proportion that die.

\  

```{r Q4, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
M1<- glm(cbind(Living_mites, Dead_mites) ~ Concentration + fToxic + Concentration : fToxic, family= binomial, data= Mites)

M1<- glm(cbind(Living_mites, Dead_mites) ~ Concentration * fToxic, family= binomial, data= Mites)
```

\  

5\. Obtain summaries of the model output using the `summary()` function. Make sure you understand the mathematical and biological interpretation of the model, by writing down the complete model on paper (with distribution and link function). What biological hypothesis does each term imply, qualitatively?

\  

```{r Q5, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
summary(M1)

coef(M1)

model.matrix(M1)

unique(model.matrix(M1))




## Mathematical model description:

# Prop_surviving ~ Binomial(Ntot, P) 
# log(P / (1-P)) = 
#         1.43 - 3.80*Concentration 
#         + 0.0085*fToxic2 + 0.014*fToxic3 + 0.27*fToxic4 
#         - 6.18*Concentration:fToxic2
#         - 1.90*Concentration*fToxic3 
#         + 1.48*Concentration*fToxic4

## "biological" hypotheses:

# (Intercept):     the mean (on the logit scale) for Toxic 1 when its
# concentration is 0 (null hypothesis not very useful, however
# the value is quite interesting, when back-transformed on the proportion
# scale: this is the proportion that survive the experiment in the absence
# of toxic chemical. Shouldn't differ between chemicals, presumably?)

# Concentration: slope of Concentration, or change in survival per unit
# increase in Toxic 1 concentration (on logit link), or change in log-odds
# of survival (on proportion scale)

# fToxic2:       difference between intercepts of Toxic 2 and Toxic 1
# fToxic3:       difference between intercepts of Toxic 3 and Toxic 1
# fToxic4:       difference between intercepts of Toxic 4 and Toxic 1

# Concentration:fToxic2  difference between Conc. slopes for Toxic 2 and
# Toxic 1. Negative means a more lethal effect than Toxic 1

# Concentration:fToxic3  difference between Conc. slopes for Toxic 2 and Toxic 1
# Concentration:fToxic4  difference between Conc. slopes for Toxic 2 and Toxic 1
```

\  

6\. Do you need to check for overdispersion? If so, how do you do it? 

\  

```{r Q6, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
# Yes, because this is a binomial variable with more than 1 trial per observation
# Residual deviance: 117.67  on 107  degrees of freedom
# -> negligible overdispersion

```

\  

7\. Do you need to perform model selection? What is the final model?

\  

```{r Q7, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE}
# we don't need to perform model selection here: given that the assay is
# to compare the effect of different chemicals, the interaction alone is the
# focus of the experiment. If it is not significant, we would have our answer
# and the simplified model wouldn't have much use.

drop1(M1, test= "Chi")

# interaction is significant: we can reject the null hypothesis that there is
# no difference between  chemicals.

```

\  

8\. Perform model validation: are you satisfied with the model?

\  


```{r Q8, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE, fig.height=8, fig.show= ifelse(SOLUTIONS, "asis", "hide")}
library(car)
vif(M1)

# extremely high VIF values: are they a problem?
# Not particularly:
# The cause probably lies with the choice of the researchers to stop increasing
# the concentration when 100% mortality was reached (or close to), leading to
# small sample size for high concentrations in the most potent chemicals.
# Nevertheless their approach was sufficient to get decent estimates of the
# curves for each treatment, with sufficient precision still to get significant
# differences. Adding more assays at higher concentrations (which presumably
# would have yield close to 100% mortality as well), for the sake of getting a
# more balanced design would make little difference to the estimates.

par(mfrow= c(3, 2))
plot(M1)

# a few complementary plots for info:

# Pearson residuals
E1<- resid(M1, type= "pearson")
F1<- fitted(M1)
plot(x= F1, y= E1, 
        xlab= "Predicted values (probability scale)", ylab= "Pearson residuals")
abline(h= 0, col= grey(0.5), lty= 2)

# The Pearson residuals are quite different from the the raw or deviance residuals in this example,
# because when predicted values are small (near p=0), the variance of the binomial distribution is very
# small. Pearson residuals being the raw residuals (difference between observed and predicted) divided
# by the sqrt of the variance (a very small value), the Pearson residuals can thus be very large even
# if the raw residual isn't.

#Independence
E1<- resid(M1, type= "pearson")
plot(x= jitter(Mites$Concentration), y= jitter(E1), 
        xlab= "Concentration", ylab= "Pearson residuals")
abline(h= 0, col= grey(0.5), lty= 2)

# Some trends in the residuals against concentration, suggesting that a straight
# line on the logit scale is not a perfect fit for these data. The model remains
# good enough for its purpose of evidencing differences in the toxicity between
# chemicals

```

\  

9\. Obtain the fitted values from the model on the scale of the response, and plot to aid model interpretation. How do you interpret the results?

\  

```{r Q9, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide")}
MyData1<- data.frame(Concentration= seq(0, 2.16, length= 50), fToxic= "1")
MyData2<- data.frame(Concentration= seq(0, 2.16, length= 50), fToxic= "2")
MyData3<- data.frame(Concentration= seq(0, 2.16, length= 50), fToxic= "3")
MyData4<- data.frame(Concentration= seq(0, 2.16, length= 50), fToxic= "4")

P1<- predict(M1, newdata= MyData1, type= "response")
P2<- predict(M1, newdata= MyData2, type= "response")
P3<- predict(M1, newdata= MyData3, type= "response")
P4<- predict(M1, newdata= MyData4, type= "response")

par(mfrow= c(1, 1)) # restore default 1x1 window
# to plot the proportion surviving, use 1 - proportion that died:
plot(x= jitter(Mites$Concentration), y= jitter(1 - Mites$Proportion), pch= 16, col= Mites$Toxic)
lines(MyData1$Concentration, P1, col= 1, lty= 1)
lines(MyData2$Concentration, P2, col= 2, lty= 1)
lines(MyData3$Concentration, P3, col= 3, lty= 1)
lines(MyData4$Concentration, P4, col= 4, lty= 1)

legend("topright", 
            legend= c("1", "2", "3", "4"), 
			lty= 1, 
			col= c(1, 2, 3, 4), bty= "n")

# All chemicals have a significant negative effect on the proportion of mites surviving, as their
# concentration increases (to ascertain this you could relevel in hindsight the least powerful chemical
# as the reference level, which will test whether its slope is significantly different from zero).
# The Chem with the highest toxicity at lower concentrations is fToxic 2, followed by fToxic 3, 1
# and 4 is the least potent.

Mites$fToxic_4AsRef<- relevel(Mites$fToxic, "4")
M2<- glm(cbind(Living_mites, Dead_mites) ~ Concentration + fToxic_4AsRef + Concentration : fToxic_4AsRef, family= binomial, data= Mites)
summary(M2)

# Concentration                 -2.3183     0.4026  -5.758 8.52e-09 ***
# shows that the negative dose-effect relationship (slope for concentration) is significant
# even for Toxic 4

# Concentration:fToxic_4AsRef1  -1.4828     0.9630  -1.540 0.123626    
# Concentration:fToxic_4AsRef2  -7.6592     2.1524  -3.558 0.000373 ***
# Concentration:fToxic_4AsRef3  -3.3826     1.1189  -3.023 0.002502 ** 
# these coefficients and their p-values show that only the dose-effect relationships of Toxics 2 and 3
# are significantly different from the dose-effect relationship of Toxic 4

```


\  

10\. (Optional) Include the 95 % CI on the plot above. You will need to obtain the fitted values and SE on the scale of the link function, calculate the CI and then back-transform.

\  

```{r Q10, eval=TRUE, echo=SOLUTIONS, results=SOLUTIONS, collapse=TRUE, fig.show= ifelse(SOLUTIONS, "asis", "hide")}
# Sketch model fit with 95% confidence bands for Toxic 1
MyData1<- data.frame(Concentration= seq(0, 2.16, length= 50), fToxic= "1")
MyData2<- data.frame(Concentration= seq(0, 2.16, length= 50), fToxic= "2")
MyData3<- data.frame(Concentration= seq(0, 2.16, length= 50), fToxic= "3")
MyData4<- data.frame(Concentration= seq(0, 2.16, length= 50), fToxic= "4")

P1<- predict(M1, newdata= MyData1, type= "link", se= TRUE)
P2<- predict(M1, newdata= MyData2, type= "link", se= TRUE)
P3<- predict(M1, newdata= MyData3, type= "link", se= TRUE)
P4<- predict(M1, newdata= MyData4, type= "link", se= TRUE)

par(mfrow= c(1, 1)) # restore default 1x1 window
plot(x= jitter(Mites$Concentration, 10), y= jitter(1-Mites$Proportion, 2), pch= 16, col= Mites$Toxic)

G1<- exp(P1$fit) / (1 + exp(P1$fit))
G1.UP<- exp(P1$fit + 1.96 * P1$se.fit ) / (1 + exp(P1$fit + 1.96 * P1$se.fit))
G1.LO<- exp(P1$fit - 1.96 * P1$se.fit) / (1 + exp(P1$fit - 1.96 * P1$se.fit))

lines(MyData1$Concentration, G1, col= 1, lty= 1)
lines(MyData1$Concentration, G1.UP, col= 1, lty= 2)
lines(MyData1$Concentration, G1.LO, col= 1, lty= 2)

# repeat the example above for all 'Toxic' levels (gets a bit busy on the graph)

legend("topright", 
            legend= c("1", "2", "3", "4"), 
			lty= 1, 
			col= c(1, 2, 3, 4), bty= "n")

# Note how the confidence intervals are and should be asymmetrical on the response scale
# (they are symmetrical on the link scale), and the logit link effectively
# prevents them from going below 0 or above 1

```

\  

End of the Binomial (Proportions) GLM - mites survival

